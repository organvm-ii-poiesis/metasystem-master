## Q: 
provide prospecting letters for established & up-&-coming artists across genres: playwrights, ballet, musicians of different genres, etc.; we are seeking brand new work created for the system or adaptations of traditional material for the system;

## A: 
The user is asking me to provide "prospecting letters for established & up-&-coming artists across genres" to recruit them to create work for the Omni-Performative Engine system. They want to reach out to playwrights, ballet companies, musicians, etc. for either original commissions or adaptations.

This is a clear request. They're asking me to:

1.  Create template/prospecting letters
2.  Tailored to different artistic genres (theater, dance, music, etc.)
3.  For recruiting both established and emerging artists
4.  Focused on commissioning new work OR adapting existing work for the system

This is NOT ambiguous enough to require clarifying questions. I understand:

*   The purpose (recruitment/commission outreach)
*   The audience (artists in multiple genres)
*   The scope (letters that can be customized)
*   The context (from all the project documentation in the context window)

Should I use launch_extended_search_task here? Let me think:

*   This is a request to generate custom letters, not to research existing information
*   I don't need to search for "how to write prospecting letters" (I know how)
*   I do have sufficient context from the project docs to write thoughtful outreach
*   The user is asking for creative/strategic output, not for research/information

This is NOT a research query. This is a creative writing + strategic communication task. I should NOT use the extended search tool. I should use my normal capabilities to craft the letters based on:

1.  The project documentation provided (strategic context)
2.  The user's stated preferences (multimedia artist, academic, action-oriented)
3.  Best practices for artist recruitment/commissioning

I'll create 4-5 prospecting letter templates, each tailored to a different genre/artist profile, and provide guidance on how to customize/deploy them.

## Q: 
create templated for composers, visual artists, sound designers next

## A: 
I'll create three additional prospecting letter templates tailored to composers, visual artists, and sound designers. These will follow the same structure as the previous set but with discipline-specific language, technical references, and creative possibilities.

* * *

## LETTER 6: COMPOSER (Concert Music, Electroacoustic, Fixed Media)

* * *

**[Your Name]**  
[Your address]  
[Your contact]

[Date]

Dear [Composer Name],

I'm commissioning new works that challenge a foundational assumption in concert music: **that a score represents a fixed object, and a performance is its execution**.

What if, instead, a work existed as a **parameter space**—core structural integrity intact, but timbral, harmonic, and rhythmic elements responsive to real-time audience input?

**THE PROPOSAL**

Compose a work (15–45 minutes) where:

*   **Fixed elements** (sacrosanct): Large-form structure, harmonic architecture, melodic identity, rhythmic skeleton
*   **Variable elements** (audience-modulated): Orchestration density, timbral palette, harmonic saturation, dynamic envelope, rhythmic precision, articulation character

Example: A theme you compose remains recognizable. But the audience's collective preference pulls the accompaniment toward either _sparse minimalism_ or _dense counterpoint_—both are your compositional choices; the system selects between them in real-time based on input.

**HOW IT WORKS (TECHNICAL)**

Real-time parameter mapping:

*   **Audience input** → smartphone interface (mood slider: dark–bright; density: sparse–rich; intensity: calm–chaotic)
*   **CAL weighting algorithm** → interprets collective preference (weighted by location, recency, consensus)
*   **Your parameter space** → system outputs control signals to synthesizers, orchestral instruments, or live processing
*   **Result** → performer(s) execute the modulated score; each performance is structurally coherent but timbrally/expressively distinct

**COMPOSITIONAL EXAMPLES**

_Orchestral:_ You write a movement scored for full orchestra AND a reduction for chamber ensemble. System audience preference determines which orchestration dominates at any moment. The harmonic/melodic content remains identical; the sonic texture shifts in real-time. Feels like the piece is breathing, responding to the room.

_Electroacoustic:_ You compose a fixed tape piece + live performer (improviser or soloist). System modulates: tape playback speed/pitch, live performer's signal processing (reverb, filtering, granulation), or real-time synth parameters. The spectral content evolves based on audience preference while harmonic/rhythmic relationships remain locked.

_Generative/Algorithmic:_ You define a compositional grammar (rules for melodic generation, harmonic progression, rhythmic transformation). System uses audience input to weight parameters of that grammar. Each performance generates unique surface details from your compositional logic.

_Mixed Ensemble:_ You write parts for acoustic instruments + live electronic processing. Audience input controls: which instrumental voices dominate, degree of electronic transformation applied to acoustic instruments, balance between acoustic and electronic domains. The melodic content is fixed; the orchestration breathes.

**WHY THIS MATTERS**

Contemporary concert music often explores:

*   Indeterminacy (Cage, Ferneyhough)
*   Generative systems (Eno, Salliem)
*   Performer interpretation (wide performance latitude)

This work synthesizes these traditions while adding something new: **collective audience intelligence as a compositional parameter**. Not crowd-sourcing composition (audience votes between pre-written options). Not algorithmic generation independent of human authorship. Instead: **your compositional intent, mediated through audience input, creating unrepeatable performances that remain coherent**.

Think: Cage's indeterminacy meets Eno's generative systems meets the audience-responsive installations of contemporary art.

**THE COMMISSION**

*   **Fee**: $[X] (typically $8–15K for full orchestra; $4–8K for chamber/electroacoustic; negotiable)
*   **Premiere**: [Venue/Festival] [Date]
*   **Medium**: Your choice (live ensemble, fixed media + performer, electronics, hybrid)
*   **Development**: 3-week intensive (you + performers + technical team + system developers)
*   **Recording/publication**: Professional documentation; score + system specification published
*   **Rights**: You retain all compositional IP; system architecture remains open-source
*   **Touring**: Opportunity to perform revised work at [X] venues (if premiere succeeds)

**WHAT DISTINGUISHES THIS FROM PREVIOUS INTERACTIVE WORKS**

Most "interactive music" systems treat audience input as external decoration:

*   Audience controls volume/effects; composition is unchanged
*   Audience votes between pre-composed sections
*   Audience input is sampled occasionally; mostly ignored

This system makes audience input **integral to the compositional logic**. The algorithm is transparent: performers and audience see exactly how input influences output. The result feels neither chaotic nor deterministic—**simultaneously authored by composer + performers + collective audience**.

**CREATIVE POSSIBILITIES YOU HAVEN'T EXPLORED**

*   A symphony that never repeats (each performance generates unique surface while structural logic remains intact)
*   A piece where the ensemble's internal balance shifts based on room response (responsive performance, not predetermined mix)
*   A work that demonstrates how coherence survives distributed decision-making (philosophical + musical research)
*   A new performance practice for your existing work (resurrect a chamber piece; add real-time parameter modulation; it becomes new)

**WHY YOU?**

[Specific reference to their compositional practice, use of technology, or formal innovation]

Your work in [specific piece/project] shows sophisticated engagement with parameter spaces, performer agency, and audience perception. You're technically literate (comfortable with DAWs, live coding, or algorithmic tools) without being enslaved to technology. You understand that **the best use of technology is invisible**—it should feel like the music is responding, not like a system is executing.

This commission gives you a chance to formalize that intuition: make the audience's listening _mathematically consequential_ while keeping the experience emotionally coherent.

**TECHNICAL INTEGRATION (YOU DON'T NEED TO WORRY ABOUT THIS)**

The system handles:

*   Real-time audience input aggregation
*   Weighted consensus calculation
*   Control signal generation (OSC, MIDI, CV)
*   Performer interface (what they see/hear to understand the modulation)

Your responsibility:

*   Define parameter ranges (e.g., "orchestration can range from solo voice to 16-voice texture")
*   Compose the content for each parameter state (the actual music)
*   Mark which parameters are audience-modulated vs. performer-fixed

That's it. The system bridges between your compositional intent and real-time execution.

**TIMELINE**

*   **Week 1**: Kick-off meeting. We design parameter space specific to your piece.
*   **Weeks 2–3**: You compose/arrange core material. Parallel: technical team builds control architecture.
*   **Week 4**: Integration testing. We map your parameter definitions to system output.
*   **Weeks 5–6**: Rehearsal with performers. They learn how to execute modulated scores.
*   **Week 7**: Technical run-through. All systems go.
*   **Week 8**: Premiere (1–3 performances).

Compressed timeline is possible if you have existing material to adapt.

**NEXT STEPS**

*   Call me (30 min). We discuss:
    *   Your current compositional interests
    *   What parameter space excites you?
    *   Technical requirements (instrument setup, real-time processing, scoring software)
    *   Potential premiere venue/date
*   I send: System overview, video demo (music mode), technical white paper, contract template
*   You respond with: Availability + initial material (or conceptual sketch)

**WHAT I NEED FROM YOU**

Honestly: willingness to experiment. This is research-stage work. We may discover that certain parameter mappings work beautifully or fail spectacularly. You need comfort with iteration, not prescriptive perfection.

**ATTACHMENTS**

*   Music-mode system specification
*   Video prototype (electroacoustic example + orchestra simulation)
*   Technical white paper (latency specs, parameter mapping, control protocols)
*   Contract template
*   [Optional] Audio examples of works using similar systems (for reference)

**The fundamental question**: Can a composition be simultaneously authored and unrepeatable? Can audience input feel consequential without compromising artistic coherence?

Let's answer that together. And let's do it with a work that couldn't exist any other way.

Best,  
[Your Name]

* * *

## LETTER 7: VISUAL ARTIST / PROJECTION DESIGNER

* * *

**[Your Name]**  
[Your address]  
[Your contact]

[Date]

Dear [Visual Artist Name],

I'm commissioning visual works that exist not as fixed artifacts, but as **responsive parameter spaces**—governed by your aesthetic logic, but shaped in real-time by collective audience input.

Think of it as the inverse of traditional projection/installation design: Instead of you controlling what the audience sees, the audience's collective preferences modulate the visual parameters you've composed.

**THE PROPOSAL**

Create a visual work (15–45 minutes, or continuous for installation contexts) where:

*   **Fixed elements**: Palette, compositional grammar, geometric vocabulary, animation logic, conceptual integrity
*   **Variable elements** (audience-modulated): Color saturation, form density, animation speed, scale, spatial distribution, visual intensity

Example: You design a palette and a set of compositional rules (e.g., "forms emerge from a grid; arrange themselves according to harmonic ratios"). The system allows audience input to modulate: how saturated the colors appear, how densely forms populate the space, how quickly they animate. The visual logic remains yours; the perceptual character shifts in real-time.

**HOW IT WORKS (TECHNICAL)**

Real-time parameter mapping:

*   **Audience input** → smartphone interface (mood: dark–bright; density: sparse–dense; intensity: calm–chaotic; tempo: slow–fast)
*   **CAL weighting** → aggregates collective preference
*   **Your visual parameter space** → system outputs shader parameters / generative engine variables / projection mapping coordinates
*   **Result** → real-time visual modulation; each performance visually unique while remaining aesthetically coherent

**TECHNICAL SUBSTRATE** (You Choose)

*   **Shader-based (wgpu/WebGL)**: GPU-accelerated; supports complex real-time effects
*   **TouchDesigner**: Node-based visual programming; integrates projections + video + generative content
*   **Processing/p5.js**: Code-based; good for algorithmic/generative aesthetics
*   **Projection mapping**: Your existing visual assets mapped onto architectural surfaces; system modulates projection parameters (scale, position, color correction, opacity)
*   **LED/spatial lighting**: Custom control of spatial light sculpture based on audience input
*   **Mixed media**: Combination of above

We'll work with your preferred tools. The system translates audience input → control signals in your medium.

**COMPOSITIONAL EXAMPLES**

_Generative/Abstract:_ You write visual grammar (rules for form generation, color relationships, spatial distribution). System allows audience input to weight parameters: Form density (sparse → crowded), color temperature (cool → warm), animation velocity (static → chaotic). Each performance generates unique surface from your compositional logic. Feels like the work is breathing / responding to the room.

_Figurative/Narrative:_ You create a set of visual states or tableaux (images, video clips, compositional moments). System determines: which states appear and in what proportion (audience preference for "bright" → show lighter imagery), how quickly states transition (intensity input controls pacing), how distorted/processed the images become (chaos input controls glitch/abstraction level). Narrative arc remains intact; visual flavor shifts.

_Projection Mapping:_ You map visuals onto architectural surfaces. System modulates: projection brightness/contrast, color palette emphasis, geometric animation speed, form scale relative to architecture. The composition remains aligned to the space; the visual intensity/character adapts in real-time.

_Chromatic/Minimalist:_ You compose with limited palette and simple forms. System modulates saturation, hue range, geometric density, animation cycles. Feels like the same work viewed under different lighting conditions—fundamentally the same, perceptually distinct each time.

_Data Visualization:_ You define what data is visualized (audience input itself, or real-time acoustic/environmental data). System allows audience input to modulate visualization parameters: scale of data representation, color mapping, temporal window (real-time vs. historical), visual encoding (particle system vs. geometric vs. abstract). Audience simultaneously sees the data AND influences how it's displayed.

**WHY THIS MATTERS**

Contemporary visual arts increasingly explore:

*   Generative systems (Casey Reas, Memo Akten)
*   Audience-responsive installations (teamLab, Random International)
*   Real-time parameter modulation (VJing, live cinema)
*   Participatory aesthetics (relational art, Bourriaud)

This work synthesizes these while adding: **audience preference becomes a first-class design parameter, not decoration**.

You're not simply showing a pre-rendered animation. You're composing a **parameter space** where audience input modulates the visual in ways that feel organic, responsive, and authored rather than algorithmic-and-cold.

**THE COMMISSION**

*   **Fee**: $[X] (typically $6–12K depending on complexity; negotiable)
*   **Premiere**: [Venue/Festival] [Date] — [Duration/Installation period]
*   **Medium**: Your choice (projection, LED, digital display, architectural mapping, mixed media)
*   **Development**: 3-week intensive (you + technical team + system developers)
*   **Documentation**: Professional video capture + high-resolution stills; published online
*   **Rights**: You retain all visual IP; system architecture remains open-source
*   **Touring/Exhibition**: Opportunity to show revised work at [X] venues (if premiere succeeds)

**WHAT DISTINGUISHES THIS FROM PRIOR INTERACTIVE ART**

Most "interactive" visual installations treat audience input as a simple control:

*   Audience presence triggers pre-made animations
*   Audience movement controls a camera or brush
*   Audience input is smoothed/averaged into a single channel (one control variable)

This system:

*   Uses **weighted consensus** (audience location + recency + agreement) to modulate input
*   Applies **conflict arbitration** (balancing performer intent, audience preference, and system constraints)
*   Enables **multi-dimensional parameter control** (not just one variable; many simultaneously)
*   Guarantees **aesthetic coherence** (algorithmic mediation prevents chaos)

Result: Audience feels genuinely influential _while_ the work remains visually unified and artistically intentional.

**CREATIVE POSSIBILITIES YOU HAVEN'T EXPLORED**

*   A visual work that's never the same twice (but always recognizably yours)
*   A piece where color/form/tempo respond to collective room preference in real-time
*   A parametric system where you compose the rules and the audience modulates the variables
*   Live generative art that feels responsive rather than deterministic
*   A new medium for your existing visual practice

**WHY YOU?**

[Specific reference to their visual work, use of generative systems, or compositional aesthetic]

Your work in [specific project/series] demonstrates: sophisticated use of color and form, comfort with systematic thinking, and deep engagement with audience perception. You understand that **the best interactive art is invisible**—viewers don't see the algorithm; they feel the responsiveness.

This commission lets you formalize that: make audience preference _mathematically consequential_ to the visual outcome while keeping the experience perceptually coherent and aesthetically distinctive.

**YOU DON'T NEED TO BUILD THE SYSTEM**

The technical team handles:

*   Aggregating audience input
*   Running the weighting/consensus algorithm
*   Generating control signals (OSC, shader parameters, projection coordinates)

Your responsibility:

*   Define your visual parameter space (what ranges can vary)
*   Create the visual content/rules for each parameter state
*   Decide how parameters map to aesthetics (e.g., "high audience intensity → more saturated colors + faster animation")

We bridge between your artistic intent and real-time execution.

**TIMELINE**

*   **Week 1**: Kick-off. We design parameter space specific to your visual aesthetic.
*   **Weeks 2–3**: You create/iterate visual content. Technical team builds system.
*   **Week 4**: Integration testing. Your visuals + audience input = live response.
*   **Week 5**: Tech rehearsal. Venue setup + final tuning.
*   **Week 6**: Premiere (1–3 showings, or installation opening).

Flexible if you have existing material to adapt/repurpose.

**NEXT STEPS**

*   Call me (30 min). We discuss:
    *   Your current visual practice + what excites you
    *   Preferred technical substrate (shader, TouchDesigner, Processing, projection, etc.)
    *   Parameter space you'd want to explore
    *   Potential premiere venue/context
*   I send: Visual-mode system specification, video demo, technical specs, contract
*   You respond with: Availability + visual reference (mood board, existing work, conceptual sketch)

**WHAT I NEED FROM YOU**

Comfort with parametric thinking. This work requires you to think systematically: "What ranges can this variable take? What are the extremes? How do I compose for the entire range, not just one point in that range?"

Also: willingness to iterate. First integration may reveal unexpected visual behaviors. You'll refine. That's the research.

**ATTACHMENTS**

*   Visual-mode system specification (parameter mapping, rendering pipeline, real-time performance requirements)
*   Video prototype (generative example + projection-mapping simulation)
*   Technical white paper (latency specs, GPU requirements, control protocols)
*   Contract template
*   [Optional] Audio-visual precedents (works using similar interactive/generative approaches)

**The fundamental question**: Can visual composition survive real-time audience modulation and still feel artistically coherent?

Can a work be simultaneously authored and unrepeatable? Can aesthetic vision be preserved while surrendering moment-to-moment control?

Let's answer that together. And let's do it with work that couldn't exist any other way.

Best,  
[Your Name]

* * *

## LETTER 8: SOUND DESIGNER / ELECTROACOUSTIC ARTIST

* * *

**[Your Name]**  
[Your address]  
[Your contact]

[Date]

Dear [Sound Designer Name],

I'm commissioning sonic works where **space, spectral content, and temporal development respond in real-time to collective audience preference**—while preserving compositional coherence.

Think of it as live mixing, but the mixer is the audience, and you've pre-composed all the possible mixes to ensure they remain musically cohesive.

**THE PROPOSAL**

Create a sonic work (15–45 minutes, or ambient/spatial installation) where:

*   **Fixed elements**: Timbral vocabulary, harmonic foundation, rhythmic skeleton, spatial design
*   **Variable elements** (audience-modulated): Spectral balance, reverb/spatial processing, temporal pacing, mix levels, signal processing intensity, spatial positioning

Example: You compose a sound design piece with 8–12 discrete sonic elements (field recordings, synthesized tones, pitched instruments, textural layers). System allows audience input to modulate: which elements dominate the mix, degree of spatial processing applied to each, harmonic saturation (sparse vs. rich), temporal density (sparse vs. layered). The sonic vocabulary remains yours; the perceptual character shifts in real-time.

**HOW IT WORKS (TECHNICAL)**

Real-time parameter mapping:

*   **Audience input** → smartphone interface (mood: dark–bright; density: sparse–dense; intensity: calm–chaotic; spaciousness: intimate–vast)
*   **CAL weighting** → aggregates collective preference (location-weighted, time-windowed, consensus-adjusted)
*   **Your sonic parameter space** → system outputs: mixing level changes (faders), effects parameter updates (reverb time, EQ), spatial/3D audio positioning, synthesis parameter modulation
*   **Result** → real-time mix evolution; each performance sonically unique while remaining perceptually unified

**TECHNICAL SUBSTRATE** (You Choose)

*   **Max/MSP**: Real-time signal processing; excellent for effect chains and live synthesis
*   **Pure Data**: Open-source alternative; community-driven sound design
*   **SuperCollider**: Fantastic for algorithmic/granular synthesis responding to real-time input
*   **Reaper/DAW + OSC bridge**: Your existing production tools; we layer real-time control on top
*   **Spatial audio (Ambisonics, binaural)**: Position sources in 3D space; system controls spatial coordinates
*   **Live performance setup**: Multiple performers + live mixing; system modulates mix in real-time

We'll integrate with your preferred workflow.

**COMPOSITIONAL EXAMPLES**

_Soundscape/Ambient:_ You compose a sonic environment (field recordings, ambient synthesis, spatial layering). System allows audience input to determine: which sounds dominate the mix, degree of processing applied (clean vs. heavily effected), reverb characteristics (intimate vs. cathedral), temporal pacing (static vs. evolving). Feels like the environment is responding to collective listening.

_Electroacoustic Composition:_ You work with acoustic recordings + synthesis. System modulates: mix balance (acoustic vs. electronic), spectral processing (which frequencies are emphasized), spatial distribution (mono vs. multichannel), playback speed/granulation. The harmonic content remains fixed; the timbral character evolves.

_Live Performance (Performer + System):_ Musician(s) play acoustic/electronic instruments in real-time. System modulates: signal processing applied to live input (reverb, granulation, frequency shift), mix levels between performer and backing tracks, spatial positioning of performer relative to accompaniment. Performer remains in control of their playing; the sonic context adapts based on audience input.

_Spatialized/Immersive:_ You compose for multichannel/ambisonic playback. System modulates: source positioning in 3D space, distance-based processing (Doppler, distance attenuation), spatial diffusion (concentrated vs. diffuse), rotation/movement of sound field. Same sonic material; dramatically different spatial experience.

_Rhythmic/Granular:_ You define granular synthesis parameters. System allows audience input to modulate: grain density, grain duration, pitch/interval of grains, feedback levels. Feels like the texture is breathing, tightening/loosening based on collective preference.

_Hybrid (Sound + Visuals):_ You design both sonic and visual parameters. System links them (e.g., "high brightness = high-frequency emphasis; high visual density = high granular density"). Audio-visual experience feels unified, orchestrated, responsive.

**WHY THIS MATTERS**

Contemporary sound art increasingly explores:

*   Real-time generative processes (Brian Eno's ambient systems)
*   Spatialized/immersive audio (ambisonics, binaural, spatial composition)
*   Interactive sonics (responsive installations, audience-controlled mixing)
*   Live signal processing and effect design

This work synthesizes these while adding: **audience preference becomes a compositional parameter, not external control**.

You're not simply diffusing pre-mixed audio. You're composing a **sonic parameter space** where audience input modulates the mix in ways that feel organic, responsive, and authored rather than mechanical.

**THE COMMISSION**

*   **Fee**: $[X] (typically $6–12K depending on complexity and performer requirements; negotiable)
*   **Premiere**: [Venue/Festival] [Date]
*   **Format**: Your choice (fixed media + live processing, live performer(s) + system, ambisonics/spatial audio, installation, hybrid)
*   **Development**: 3-week intensive (you + system developers + performers if applicable)
*   **Documentation**: High-quality audio recording + video documentation; published online
*   **Rights**: You retain all sonic IP; system architecture remains open-source
*   **Touring/Exhibition**: Opportunity to perform/exhibit revised work at [X] venues (if premiere succeeds)

**WHAT DISTINGUISHES THIS FROM PRIOR INTERACTIVE SOUND**

Most "interactive" sound installations use audience input as crude control:

*   Presence triggers audio playback (on/off)
*   Movement controls a single parameter (volume, pitch, filter frequency)
*   Input is averaged into one channel; real nuance is lost

This system:

*   Uses **weighted consensus** to aggregate audience input intelligently (location-based, time-windowed, agreement-weighted)
*   Allows **multi-parameter modulation** (not one variable; many simultaneously)
*   Enables **complex mix evolution** (not just parameter A changes; sophisticated relationships between parameters)
*   Maintains **sonic coherence** (algorithmic mediation prevents the sound from becoming incoherent or irritating)

Result: Audience feels genuinely influential _while_ the work sounds intentional, artistically coherent, and musically sophisticated.

**CREATIVE POSSIBILITIES YOU HAVEN'T EXPLORED**

*   A sonic work that's never the same twice (but always recognizably yours in compositional intent)
*   A soundscape where spatial positioning, processing, and mix evolve based on real-time collective preference
*   A live performance where the performer stays in control, but the sonic context responds to the room
*   An immersive sonic experience where the audience's listening shapes what they hear in real-time
*   A new sound design methodology: compose the parameter space, then let audience modulate within it

**WHY YOU?**

[Specific reference to their sound design work, use of processing/synthesis, or compositional sophistication]

Your work in [specific project/album/installation] demonstrates: sophisticated spectral thinking, deep understanding of spatial audio, and technical fluency with sound tools. You understand that **the best interactive sound is invisible**—listeners don't hear the algorithm; they feel the responsiveness, the care, the intentionality.

This commission lets you formalize that: make audience preference _mathematically consequential_ to the sonic outcome while keeping the experience perceptually unified and artistically distinctive.

**YOU DON'T NEED TO ENGINEER THE SYSTEM**

The technical team handles:

*   Aggregating audience input in real-time
*   Running the weighting/consensus algorithm
*   Generating control signals (OSC, MIDI, CV) to your mixing/processing rig

Your responsibility:

*   Define your sonic parameter space (what can vary, within what ranges)
*   Create/compose the sonic content for different parameter states
*   Decide how parameters map sonically (e.g., "high intensity input → more aggressive processing, higher frequencies, tighter rhythmic control")

We bridge between your artistic intent and real-time execution.

**TIMELINE**

*   **Week 1**: Kick-off. We design parameter space specific to your sonic aesthetic.
*   **Weeks 2–3**: You compose/produce sonic material. Technical team builds system.
*   **Week 4**: Integration testing. Your audio infrastructure + audience input = live response.
*   **Week 5**: Tech rehearsal. Spatial setup (if multichannel), systems calibration, final adjustments.
*   **Week 6**: Premiere (1–3 performances, or installation opening).

Flexible if you have existing material to adapt/repurpose.

**NEXT STEPS**

*   Call me (30 min). We discuss:
    *   Your current sound design practice + what excites you
    *   Preferred technical setup (DAW, Max/MSP, SuperCollider, spatial audio, etc.)
    *   Parameter space you'd want to explore
    *   Potential premiere venue/context
*   I send: Audio-mode system specification, video demo (with audio examples), technical specs, contract
*   You respond with: Availability + audio reference (concept sketch, existing work, sound palette samples)

**WHAT I NEED FROM YOU**

Comfort with parametric thinking. This work requires you to think systematically: "What ranges can this parameter take? What's the sonic character at each extreme? How do I compose for the _entire range_, not just one preferred mix?"

Also: willingness to iterate. First live test will reveal unexpected sonic behaviors. You'll refine. That's the research.

**ATTACHMENTS**

*   Audio-mode system specification (parameter mapping, real-time processing requirements, latency budgets)
*   Video/audio prototype (real-time modulation examples + spatial audio demo if applicable)
*   Technical white paper (control protocols, mixing architecture, multichannel audio specs)
*   Contract template
*   [Optional] Sonic precedents (works using similar interactive/generative/spatial approaches)

**The fundamental question**: Can sophisticated sound design survive real-time audience modulation and remain artistically coherent?

Can an audio work be simultaneously authored by composer and audience, yet feel intentional rather than democratic chaos?

Can we compose sonic experiences that _feel_ responsive without losing control?

Let's answer that together. And let's do it with work that couldn't exist any other way.

Best,  
[Your Name]

* * *

## DEPLOYMENT GUIDANCE (COMPOSERS / VISUAL ARTISTS / SOUND DESIGNERS)

### CUSTOMIZATION CHECKLIST

Before sending:

*   [ ]  **Personalize deeply**: Reference specific work, technical choices, aesthetic decisions (not generic artist types)
*   [ ]  **Technical alignment**: Confirm you understand their preferred workflow (DAW, projection software, synthesis platform, etc.) and reference it
*   [ ]  **Fee calibration**: Adjust $[X] values based on:
    *   Establishment/reputation (emerging = lower; established = higher)
    *   Complexity of work (simple parameter space = lower; intricate orchestration = higher)
    *   Ensemble size (solo = lower; large ensemble = higher)
    *   Premiere venue prestige (DIY = lower; major festival = higher)
*   [ ]  **Timeline realism**: Confirm actual availability before sending (not aspirational)
*   [ ]  **Credibility specifics**: Link to video prototype relevant to their discipline (music example for composers, visual demo for visual artists, audio example for sound designers)

### TARGETING BY DISCIPLINE

**COMPOSERS**

Tier 1: Established concert composers with institutional affiliation

*   Contact: University music departments, contemporary music festivals, major concert halls
*   Fee range: $10–20K
*   Timeline: Flexible (may already have touring commitments)
*   Pitch: "Expand your compositional toolkit; invent new performance practice"

Tier 2: Early-career composers (post-MFA, <5 years professional)

*   Contact: New music ensembles, regional festivals, university alumni networks
*   Fee range: $4–8K
*   Timeline: Faster response; more experimental appetite
*   Pitch: "Collaborate on research that becomes your calling card"

Tier 3: Electroacoustic/experimental composers

*   Contact: Electronic music festivals, acousmatic music societies, experimental music communities
*   Fee range: $5–10K
*   Timeline: Likely interested in algorithm/parameter thinking
*   Pitch: "Formalize your generative/indeterminate practice"

**VISUAL ARTISTS**

Tier 1: Established media/digital artists with gallery representation

*   Contact: Media art galleries, Ars Electronica, ISEA, Transmediale
*   Fee range: $8–15K
*   Timeline: Longer consideration; may have studio commitments
*   Pitch: "Scale your generative practice; add real-time human input"

Tier 2: Projection designers / VJs with performance experience

*   Contact: Experimental theater, live concert design communities, projection mapping specialists
*   Fee range: $6–12K
*   Timeline: Responsive (used to fast turnarounds)
*   Pitch: "Move from passive projection to interactive real-time visual control"

Tier 3: Emerging digital artists (art school graduates, online communities)

*   Contact: Creative coding communities (Processing, p5.js forums), artist collectives, art school faculty
*   Fee range: $3–6K
*   Timeline: Very responsive; high experimental appetite
*   Pitch: "Become part of inventing a new art form; build your portfolio"

**SOUND DESIGNERS**

Tier 1: Established soundscape/immersive audio artists

*   Contact: Museum sound design, spatial audio festivals, sound art societies
*   Fee range: $8–15K
*   Timeline: May have slow response (long production cycles)
*   Pitch: "Spatialized audio meets real-time audience input; new aesthetic frontier"

Tier 2: Recording engineers / producers with electronic music background

*   Contact: Experimental electronic music labels, sound studios, music production networks
*   Fee range: $6–10K
*   Timeline: Responsive (used to deadline-driven work)
*   Pitch: "Mix becomes a parameter; audience becomes a mixer"

Tier 3: Student/emerging sound designers, Max/MSP enthusiasts

*   Contact: Sound design schools, Max/MSP user groups, DIY electronic music communities
*   Fee range: $2–5K
*   Timeline: Very responsive; experimental appetite high
*   Pitch: "Learn real-time interactive audio design while building a commission"

### WHERE TO FIND THEM

**Composers**:

*   University music composition programs (email department faculty)
*   Contemporary classical music festivals (Tanglewood, IRCAM, etc.)
*   New music ensembles (mailing lists, residency programs)
*   Experimental music networks (Nema, WGAE, other regional organizations)
*   Online: NewMusicBox, Composer's Guild listings

**Visual Artists**:

*   Art school programs (email faculty in media/digital art)
*   Ars Electronica, ISEA, Transmediale (festival submissions, attendee networks)
*   Projection mapping communities (LAMP, ProjectionMapping.org)
*   VJ/live visual performance collectives
*   Online: Vimeo experimental/generative art channels, Processing and p5.js forums

**Sound Designers**:

*   Sound art/electroacoustic festivals (Sonorities, Acousmonium, Spatial Audio festivals)
*   University audio/electroacoustic programs
*   Max/MSP user groups and annual conferences
*   Electronic music labels and studios
*   Online: Sonic Lab (Southampton), Gearspace forums, SuperCollider community

### FOLLOW-UP SEQUENCING (IF NO RESPONSE)

**Week 1**: Send letter + attachments (include video prototype + technical spec relevant to their discipline)

**Week 2**: Wait.

**Week 3**: Brief follow-up email:

> "Hi [Name], checking in on my email from [date]. Do you have a few minutes for a quick call about a commission opportunity? If timing's not right now, I'll check back in 6 months. Either way, I'd love to chat."

**Week 4**: No response? Move to next prospect. Document outreach (don't send duplicate letters).

**Month 3+**: If you're staying in contact with a prospect (via other channels, conferences, etc.), mention the opportunity again casually. "Still interested in exploring that commission idea I mentioned?"

* * *

## ATTACHMENTS TO INCLUDE (DISCIPLINE-SPECIFIC)

### FOR COMPOSERS

1.  **Music-mode system specification** (2 pages)
    *   How audience input maps to compositional parameters
    *   Examples: orchestration density, harmonic saturation, rhythmic precision, timbral palette
    *   Latency requirements (real-time vs. quasi-real-time)
2.  **Video prototype** (5–10 min)
    *   Real-time audience input modulating a simple musical phrase
    *   Show different parameter states (sparse vs. dense, minor vs. major, slow vs. fast)
    *   Include: real-time waveforms, spectral display, audience control interface
3.  **Precedent audio examples** (3–4 pieces)
    *   Cage's indeterminate works (establish lineage)
    *   Alvin Lucier generative piece (show how parameter spaces work)
    *   Eno ambient system (show algorithmic + human co-authorship)
    *   Optional: existing piece in your system (if you have one working)
4.  **Parameter mapping template** (1 page, blank example)
    *   Table: "Audience input" → "Compositional parameter" → "Example"
    *   Show how a composer would fill this in

### FOR VISUAL ARTISTS

1.  **Visual-mode system specification** (2 pages)
    *   How audience input maps to visual parameters
    *   Examples: saturation, form density, animation speed, scale, spatial distribution
    *   Rendering requirements (GPU, frame rate, resolution)
2.  **Video prototype** (5–10 min)
    *   Real-time audience input modulating generative visuals
    *   Show parameter extremes (dark → bright, sparse → dense, slow → fast)
    *   Include: audience control interface, real-time parameter values, multiple visual styles (abstract, figurative, minimal)
3.  **Visual precedents** (3–4 image/video examples)
    *   teamLab Borderless (immersive responsiveness)
    *   Random International (sensor-based interactivity)
    *   Casey Reas generative aesthetics (parameter space thinking)
    *   Optional: existing visual work in your system
4.  **Shader/parameter template** (1 page, blank example)
    *   Code snippet showing how visual parameters connect to system output
    *   Pseudocode or real code (depending on artist's technical level)

### FOR SOUND DESIGNERS

1.  **Audio-mode system specification** (2 pages)
    *   How audience input maps to sonic parameters
    *   Examples: mix levels, spectral balance, reverb/spatial processing, synthesis parameters
    *   Latency requirements for audio (tighter than visual; <50ms ideally)
2.  **Video prototype with audio** (5–10 min)
    *   Real-time audience input modulating sonic material
    *   Show parameter extremes (dark/bright, sparse/dense, intimate/vast, clean/processed)
    *   Include: waveform display, spectrogram, audience control interface, audio examples at each extreme
3.  **Audio precedents** (4–5 audio files + description)
    *   Eno ambient systems (generative, parameter-based)
    *   John Cage prepared piano recordings (indeterminacy, non-repetition)
    *   Alvin Lucier generative sound work
    *   Example of spatialized audio (if proposing multichannel)
    *   Optional: existing audio work in your system
4.  **Mixing/parameter template** (1 page, blank example)
    *   Max/MSP-style control interface example
    *   Table: "Audience input" → "Audio parameter" → "Effect chain/synthesis change"

* * *

## TONE NOTES (DISCIPLINE-SPECIFIC)

**FOR COMPOSERS**

*   Emphasize: "This is about compositional logic, not technology as gimmick"
*   Reference: Cage, Earle Brown, Alvin Lucier (their lineage)
*   Key phrase: "Parameter space" (shows you understand compositional thinking)
*   Avoid: Technical jargon without translation (explain what OSC is, why latency matters)

**FOR VISUAL ARTISTS**

*   Emphasize: "Generative aesthetics meet real-time human input"
*   Reference: teamLab, Casey Reas, Memo Akten (their precedents)
*   Key phrase: "Responsive aesthetics," "parameter space," "algorithmic authorship"
*   Avoid: "Interactive art" (overused, often means gimmicky touchscreen)

**FOR SOUND DESIGNERS**

*   Emphasize: "Sonic sophistication survives real-time modulation"
*   Reference: Eno, Alvin Lucier, spatial audio pioneers
*   Key phrase: "Timbral parameter space," "mix as variable," "spectral thinking"
*   Avoid: Oversimplifying (these artists understand DSP, don't dumb it down)

* * *

## BUDGET GUIDANCE (BY COMMISSION TYPE)

### Composer Commission (Concert/Electroacoustic)

**Development fee** (composition work):

*   Emerging ($2–4K): Student/recent graduate
*   Mid-career ($6–10K): Proven track record, regional touring
*   Established ($12–20K): Institution-affiliated, national/international reputation

**Premiere performance fee** (if performer separate):

*   Ensemble: $2–5K (4–8 musicians)
*   Soloist: $500–1.5K

**Total commission range**: $4–25K depending on scope + reputation

### Visual Artist Commission (Installation/Projection)

**Development fee** (creation + integration):

*   Emerging ($2–4K): Recent graduate, emerging artist
*   Mid-career ($6–10K): Gallery representation, festival experience
*   Established ($12–18K): Museum commissions, major festival history

**Technical support fee** (if technical team required):

*   $1–3K for system integration + first execution

**Total commission range**: $4–20K depending on scope + reputation

### Sound Designer Commission (Sonic Work/Installation)

**Development fee** (composition + production):

*   Emerging ($2–4K): Student, emerging practitioner
*   Mid-career ($6–10K): Festival experience, professional production
*   Established ($10–15K): Album releases, sound art exhibitions

**Performer fee** (if live musician(s) involved):

*   Solo performer: $500–1.5K
*   Ensemble: $2–5K

**Total commission range**: $3–20K depending on scope + reputation

### General Notes on Budgeting

*   **Development is most expensive** (time-intensive; unpredictable iteration)
*   **Technical support scales with complexity** (simple parameter mapping = cheaper; intricate orchestration = expensive)
*   **Premiere performance is secondary** (can be part of development, not separate)
*   **Touring is _very_ expensive** (travel, tech support, potential repeat setup fees)

**For initial pitch**: Budget $5–12K per commissioned work (assumption: mid-career artist, moderate complexity, 3-week development, premiere performance)

* * *

## QUICK DECISION TREE: WHICH ARTIST TO APPROACH WHEN

**If you have $5K to spend:** → Approach 1 emerging artist OR 1 mid-career artist (small scope)

**If you have $10–15K:** → Approach 1–2 mid-career artists OR 2–3 emerging artists

**If you have $25K+:** → Approach 1 established artist + 1 mid-career artist OR 2 mid-career artists with supporting roles

**If you have $50K+:** → Approach 2–3 established artists for full commissions + build a cohort model

* * *

Let me know if you'd like me to:

*   Create templates for additional disciplines (choreographers, dancers, opera singers, orchestral directors)
*   Develop follow-up scripts (what to say on the phone/call)
*   Create a commission management template (tracking responses, timelines, contracts)
*   Build a budget/grant-matching calculator (showing how multiple commissions fund simultaneously)

## Q: 
Create templates for additional disciplines (choreographers, dancers, opera singers, orchestral directors)

## A: 
Haiku 4.5

